## 1.说说hive的优化
1. hive存储压缩优化，比如使用parquet + lzo 或 orc + snappy
2. 表连接的时候，使用小表join大表 (因为可以减少磁盘的读取次数)
3. 表连接或者汇总计算的时候避免数据倾斜:
	   a.表连接可以使用map join 避免数据倾斜
	   b.汇总计算group by 可以使用负载均衡
	或者把倾斜的数据单独拿出来计算
	   c.当空值很多的时候可以过滤空值或者通过添加随机数改变空值
4. 用GROUP BY + COUNT 代替 Count(Distinct) 去重统计
5. 避免使用笛卡尔积
6. 行列裁剪：先where筛选，再进行连接计算; select只选择需要的字段
7. 合理使用分区分桶表
8. 合理设置map数：
	当小文件过多的时候，可以通过合并小文件减少map数量
	set mapred.max.split.size=112345600;        
	--最大切片大小
	-set mapred.min.split.size.per.node=112345600;
	--每个节点最小切片大小
	set mapred.min.split.size.per.rack=112345600; 
	--每个机架的最小切片大小
	set hive.input.format= org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
	--小文件合并
	当文件比较大的时候，可以增加map数
	set mapreduce.input.fileinputformat.split.maxsize=10485760; --设置切片大小
9. 合理设置reduce数:
	N=min(1009，总输入数据量/256M)
	set mapreduce.job.reduces=N;
11. 开启并行执行：set hive.exec.parallel=true;
12. 使用严格模式
## 2.hdfs的读写流程
### 读流程
1. 客户端先带着要读取的数据的路径向nn发送请求
2. nn返回有这个数据的dn节点信息的列表
3. 客户端向dn发送读取的请求
4. dn返回同意读取的响应
5. 客户端开始发送读取的请求，指定要读取的内容
6. dn返回你要读取的数据
如果数据的大小超过了128M，那么第五和第六步会反复的进行数据块的读取。
### 写流程
1. 客户端向nn发送数据的写入请求
2. nn对数据进行校验
3. nn返回同意写入的响应
4. 客户端开始准备写入数据
5. nn返回可以写入数据的dn节点信息的列表
6. 客户端根据列表信息找到最近机架的随机机器进行数据的写入申请
7. dn返回同意写入
8. 客户端开始发送数据
	8.1 dn向同机架的随机机器进行数据的备份，同时向其他机架的随机机器进行数据的备份
9. dn返回给客户端写入成功的响应

如果写入的数据超过了128M，第六到第九步是反复执行的。
## 3.yarn资源调度流程
1. 客户端先要发送一个计算的请求给到RM
2. RM收到之后让NM下发一个容器
3. 在容器里面会产生一个AM
4. AM会检查当前的资源是否足够完成计算，如果不够就继续向RM申请资源，RM会向NM申请再下发一个容器
5. AM申请到足够的资源之后，开始计算，并且同时向RM发送心跳包
6. 如果RM没有收到心跳包，就说明AM计算已经完成了
7. RM就会发申请给NM要求回收已经下发的容器
## 4.mapreduce计算流程
input：获取要被计算的数据(读数据)
split：对整个大的数据进行拆分，拆分N个部分(拆分数据)
map：将拆分好的数据，映射到不同的reduce进程上，分配工作量和任务(映射数据)
shuffle：按照哈希算法，mod(哈希值,reduce个数)，余数相同的数据会洗到一起
reduce：对数据进行整合(计算阶段)
finalize：将数据格式化输出展示
## 5.星型模型和雪花模型有什么区别
### 模型连接方式
- 一对多：一方通常为主键，没有重复值；多方为外键，有重复值。(数据可能会，也有可能不会,具体要看计算的口径)
- 多对一：与一对多一样(数据可能会，也有可能不会,具体要看计算的口径)
- 一对一：2 张表的 key 都没有重复值(数据不会发生膨胀)
- 多对多：2 张表的 key 都有重复值(数据一定会发生膨胀)
### 星型模型
当所有的<span style="background:#d3f8b6">维度表</span>都是和<span style="background:#d3f8b6">事实表</span><span style="background:#fdbfff">直接相连</span>的时候，整个图形看上去就像是一个星星，我们称之为<span style="background:#b1ffff">星型模型</span>。因为每一个维度都和事实表直接相连，<span style="background:#b1ffff">不存在渐变维度</span>，所以有一定的<span style="background:#b1ffff">数据冗余</span>，因为有数据的冗余，很多的统计情况下，<font color="#00b0f0">不需要</font>在和其他的表进行<font color="#00b0f0">关联</font>查询，因此<font color="#00b0f0">效率</font>相对<font color="#00b0f0">较高</font>。
#### 优点：
由于维度表和事实表<font color="#4bacc6">直接</font><font color="#4bacc6">连接</font>，因此模型相对比较简单，sql 逻辑也会相对简单，因此查询性能相对较高。
#### 缺点：
数据冗余
### 雪花模型
当有多个<span style="background:#b1ffff">维度表没有直接和事实表相连</span>，而是通过其它的维度表，<span style="background:#b1ffff">间接</span>的连接在事实表上，其图形就像是一个雪花，因此我们称之为雪花模型，雪花模型的优点是<span style="background:#b1ffff">减少了数据冗余</span>，在办进行数据统计
#### 优点：
减少了数据冗余
#### 缺点：
由于维度表和事实表<font color="#4bacc6">间接连接</font>，因此模型相对比较复杂，sql 逻辑也会相对复杂，因此查询性能会相对较低
## 6.什么是三范式![[数仓建模.pdf]]
三范式规范关系型数据库设计的理论
<span style="background:#fdbfff">第 1 范式</span>：原子性，列不可再分
<span style="background:#fff88f">第2 范式</span>：在满足 1NF 的前提下，表中不存在部分依赖，非主键列要完全依赖于主键。(主要是说在联合主键的情况下，非主键列不能只依赖于主键的一部分)
<span style="background:rgba(173, 239, 239, 0.55)">第 3 范式</span>：在满足第二范式的基础上，<font color="#00b0f0">消除</font>非主键字段之间的<font color="#00b0f0">传递依赖</font>。它要求每个非主键字段<font color="#00b0f0">只依赖于主键</font>，而不依赖于其他非主键字段
## 7.维度建模的4个步骤
选择业务产品视角（如存款、贷款、账户等） → 声明粒度 → 确定维度 → 确定事实

例如业务经常要看每天的贷款情况统计，所以我们设计了贷款账户汇总宽表：

a.选择一个业务产品视角，贷款

b.因为是每天的，所以粒度为天

c.设计宽表既要满足当下的业务需求，也要满足后续的可扩展性，所以维度有贷款账号，合同浮动利率类型，产品代码，客户编号，币种代码，操作员代码，五级分类，贷款种类等

d.确实事实：有贷款金额，贷款余额，本月应收本金，本月实收本金，本金罚息，利息罚息，当月累计利息收入金额，当周累计利息收入金额，还款期数等

根据上面的四个步骤，构建一个总线矩阵，然后去上游进行表格探源，找出相关的表，维度表有客户信息表，信贷评级信息表，对公客户信息表，信贷类合同信息表，事实表有借据表，还款计划表，还款流水表，借据动态信息表等。通过雪花模型或星型的方式把维度表和事实表关联在一起。
## 8.oracle中有使用过游标吗，你们游标用的多不多
- **批量数据处理**：当需要逐行处理大量数据时（如ETL过程中的复杂转换）例如更改表名
## 9.知道oracle的hints优化器吗
oracle中的hints优化器会自动把[三种关联机制](obsidian://open?vault=LIUXIAOXIN&file=%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%2Fhints%E4%BC%98%E5%8C%96%E5%99%A8)都试一遍，选择一种最优的机制